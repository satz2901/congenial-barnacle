{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment analysis",
      "provenance": [],
      "authorship_tag": "ABX9TyMP+bfJIGwh6IXPn0v9moCL"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5ro9rBNxTK5"
      },
      "source": [
        "\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "#function helps to predict the text\n",
        "def predict(text):\n",
        "  encoded_text=encode_text(text)\n",
        "  pred=np.zeros((1,250))\n",
        "  pred[0]=encoded_text\n",
        "  result=model.predict(pred)\n",
        "  print(result[0])\n",
        "\n",
        "#basic initialization and loading data\n",
        "VOCAB_SIZE=88584\n",
        "MAXLEN=250\n",
        "BATCH_SIZE=64\n",
        "(train_data,train_labels),(test_data,test_labels)=imdb.load_data(num_words=VOCAB_SIZE)\n",
        "\n",
        "#preprocessing test data and train data\n",
        "train_data=sequence.pad_sequences(train_data,MAXLEN)\n",
        "test_data=sequence.pad_sequences(test_data,MAXLEN)\n",
        "\n",
        "#creating the model\n",
        "\n",
        "model=tf.keras.Sequential([\n",
        "                           tf.keras.layers.Embedding(VOCAB_SIZE,32),\n",
        "                           tf.keras.layers.LSTM(32),\n",
        "                           tf.keras.layers.Dense(1,activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# can use model.summary() to find summary of the created model \n",
        "\n",
        "#TRAINING\n",
        "#compiling the model , can use adam or rmsprop as optimizer ,both works fine\n",
        "model.compile(loss=\"binary_crossentropy\",optimizer=\"rmsprop\",metrics=['acc'])\n",
        "history=model.fit(train_data,train_labels,epochs=10,validation_split=0.2)\n",
        "\n",
        "#may or not use this statement , it is only to evalute model to see how well it performs \n",
        "result=model.evaluate(test_data,test_labels)\n",
        "print(result)\n",
        "\n",
        "word_index=imdb.get_word_index()\n",
        "#function helps to encode text into numberic values\n",
        "def encode_text(text):\n",
        "  tokens=keras.preprocessing.text.text_to_word_sequence(text)\n",
        "  tokens=[word_index[word] if word in word_index else 0 for word in tokens]\n",
        "  return sequence.pad_sequences([tokens],MAXLEN)[0]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "positive_review=input()\n",
        "\n",
        "predict(positive_review)\n",
        "\n",
        "negative_review=input()\n",
        "\n",
        "predict(negative_review)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmKfz2scGj3D"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaDC-L6oDj34"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}